# Planejamento da Avaliação do Protótipo de Papel

## Introdução

A avaliação de protótipos é essencial no design centrado no usuário, permitindo identificar problemas de usabilidade e validar soluções antes de avançar para estágios mais complexos. Este documento apresenta o planejamento da avaliação de protótipos de papel, um método eficaz e acessível para explorar ideias iniciais e coletar feedback dos usuários, utilizando o framework DECIDE para estruturar o processo e garantir resultados aplicáveis ao aprimoramento do protótipo.

## Objetivo

O objetivo desta avaliação é validar a usabilidade e a eficácia do protótipo de papel desenvolvido, identificando problemas na interface e na interação com o usuário, bem como avaliando diferentes ideias e alternativas de design. O foco é coletar impressões sobre a clareza e a praticidade do protótipo.

## Metodologia

Será utilizado o framework DECIDE para o planejamento dessa avaliação, estruturando o processo em seis etapas a serem seguidas.

<font size="3"><p style="text-align: left">**Figura 1** - Framework DECIDE.</p></font>

![Figura do framework DECIDE](../../../assets/Framework_DECIDE.jpeg)

Autor(es): [Felipe Rodrigues](https://github.com/felipeJRdev) e [João Vitor](https://github.com/Jauzimm), 2025.

## D - Determinar os objetivos

Determinar os objetivos de IHC é essencial para criar interfaces eficientes, acessíveis e alinhadas às necessidades dos usuários. Nesta avaliação, o foco será no protótipo de papel, uma ferramenta de prototipagem de baixo custo e baixa fidelidade, que permite explorar rapidamente ideias e identificar oportunidades de melhoria. Os principais pontos a serem abordados são:
- **Ideias e alternativas de design**: Serão exploradas soluções que melhor atendam às expectativas dos usuários e promovam clareza e satisfação.
- **Problemas na interação e na interface**: Identificar e corrigir barreiras que dificultam o uso, contribuindo para uma experiência mais intuitiva.

## E - Explorar as perguntas

Explorar as perguntas a serem respondidas é fundamental para orientar a avaliação de IHC, pois elas ajudam a entender como cada protótipo impacta a experiência do usuário, identificando quais elementos funcionam bem e quais precisam ser ajustados. O uso do protótipo de papel permite testar essas perguntas de forma rápida e econômica, facilitando a exploração de diferentes alternativas de design e a identificação de problemas na interface antes de avançar para versões mais complexas. Ele proporciona feedback imediato dos usuários, possibilitando ajustes rápidos e assegurando que o design esteja alinhado com as expectativas e necessidades do público-alvo.

<font size="3"><p style="text-align: left">**Tabela 1**: Perguntas do pontos escolhidos.</p></font>

| **Objetivo** | **Pergunta Avaliativa** | **Respostas** |
|:------------:|-------------------------|---------------|
| **ideias e alternativas de design** | Qual das alternativas é mais eficiente para os usuários? |  |
| | Qual alternativa facilita mais a tarefa do usuário, reduzindo o esforço necessário? |  |
| | Qual delas os usuários preferem? Por quê? |  |
| **Identificar problemas na interação e interface** | Existem elementos do protótipo que confundem o usuário ou geram dúvidas? |  |
| | Que tipos de erros os usuários cometeram ao interagir com o protótipo? |  |
| | Algum elemento do protótipo impede que o usuário complete suas tarefas simuladas? |  |
| | O usuário entende o que deve fazer em seguida? |  |

Autor(es): [Felipe Rodrigues](https://github.com/felipeJRdev) e [João Vitor](https://github.com/Jauzimm), 2025.

## C - Escolher (Choose)

Para avaliar os protótipos, será utilizado o método de investigação, que inclui observação dos usuários ao interagir com o protótipo de papel. Esse método permite entender as percepções, preferências e dificuldades dos usuários, ajudando a identificar problemas no design e na interação.

## I - Identificar e Administrar as Questões Práticas da Avaliação

### Recrutamento

Para o recrutamento, serão selecionadas cinco pessoas, uma para cada protótipo de papel desenvolvido pelos integrantes do grupo. O público-alvo será definido com base no perfil de usuário identificado durante a análise de requisitos. As entrevistas serão conduzidas de forma presencial, garantindo a realização adequada das atividades planejadas.

### Preparação

Os entrevistadores realizarão um teste piloto para assegurar que as dinâmicas e os materiais estão em conformidade com os objetivos da avaliação. Durante a avaliação formal, os entrevistadores seguirão um roteiro estruturado de perguntas para conduzir as entrevistas.

Os entrevistadores serão responsáveis pela aplicação das perguntas e pelo registro das respostas dos usuários. As entrevistas incluirão atividades relacionadas aos artefatos dos protótipos de papel. Os papéis podem ser divididos entre uma ou duas pessoas, com uma pessoa formulando as perguntas e outra coletando as respostas.

### Custos

Os recursos necessários para a avaliação incluem dispositivos com acesso à internet, como notebooks ou computadores, para gravação das entrevistas e documentação dos resultados. Além disso, os custos abrangem o deslocamento até o local da entrevista e os equipamentos utilizados, quando aplicável.

### Prazos

Cada entrevistador conduzirá uma sessão com duração aproximada de 10 minutos. O cronograma será ajustado conforme a disponibilidade dos participantes, com todas as sessões previstas para ocorrerem no intervalo entre os dias 06 e 14 de janeiro de 2025.

<font size="3"><p style="text-align: left">**Tabela 2**: Cronograma da Entrevista.</p></font>

| Entrevistador(es)                       | Entrevistado(s)           | Horário de Início | Horário de Fim | Data       | Local                                      |
|:--------------------------------------:|:-------------------------:|:----------------:|:--------------:|:----------:|:------------------------------------------:|
| [Felipe Rodrigues](https://github.com/felipeJRdev)  | A definir                | A definir       | A definir     | 06/01/2025 - 14/01/2025 | Universidade de Brasília Campus Gama       |
| [Jéssica Eveline](https://github.com/xzxjesse)      | A definir                | A definir       | A definir     | 06/01/2025 - 14/01/2025 | Universidade de Brasília Campus Gama       |
| [João Vitor](https://github.com/Jauzimm)            | A definir                | A definir       | A definir     | 06/01/2025 - 14/01/2025 | Universidade de Brasília Campus Gama       |
| [Ruan Carvalho](https://github.com/Ruan-Carvalho)   | A definir                | A definir       | A definir     | 06/01/2025 - 14/01/2025 | Universidade de Brasília Campus Gama       |
| [Marcelo Adrian](https://github.com/Marcelo-Adrian) | A definir                | A definir       | A definir     | 06/01/2025 - 14/01/2025 | Universidade de Brasília Campus Gama       |

Autor(es): [Felipe Rodrigues](https://github.com/felipeJRdev) e [João Vitor](https://github.com/Jauzimm), 2025.

## D - Decidir como lidar com as questões éticas

Os participantes serão informados sobre os objetivos da avaliação e o uso de suas respostas. Um [termo de consentimento](https://interacao-humano-computador.github.io/2024.2-Grupo05/entregas/entrega_2/aspectos_eticos/#termo-de-consentimento) será apresentado, garantindo o sigilo e a utilização ética das informações coletadas.

## E - Avaliar (Evaluate)

Após a coleta de dados, as respostas serão analisadas para identificar padrões e discrepâncias. O avaliador considerará a confiabilidade dos dados, a validade interna, externa e ecológica do estudo, garantindo que os resultados sejam consistentes, precisos e aplicáveis a contextos semelhantes. Os problemas identificados serão classificados por gravidade, e as sugestões dos participantes serão priorizadas para a implementação de melhorias no CD-MOJ.

## Planejamento do teste piloto

Antes de realizar a avaliação completa, é fundamental conduzir um teste piloto. Esse teste tem como objetivo validar o planejamento da avaliação, garantir que todos os procedimentos estão claros e funcionais, e permitir ajustes necessários. Além disso, o teste piloto ajuda a identificar possíveis falhas nos métodos, questões de usabilidade e a eficácia do roteiro de entrevista. Segue a tabela abaixo com a marcação do teste piloto.

<font size="3"><p style="text-align: left">**Tabela 3**: Tabela do planejamento do teste piloto.</p></font>

| Ordem | Data       | Horário de Início e Fim | Local                              | Entrevistadores | Entrevistado |
|:-----:|:----------:|:-----------------------:|:----------------------------------:|:---------------:|:------------:|
|   1   | A definir | A definir          | Universidade de Brasília Campus Gama | A definir | A definir |

Autor(es): [Felipe Rodrigues](https://github.com/felipeJRdev) e [João Vitor](https://github.com/Jauzimm), 2025.

## Bibliografia

Barbosa, S. D. J.; Silva, B. S. da; Silveira, M. S.; Gasparini, I.; Darin, T.; Barbosa, G. D. J. (2021) Interação Humano-Computador e Experiência do usuário. Autopublicação.

## Histórico de Versão

| Versão |               Descrição                |   Autor    |    Data    |    Revisor     | Data de revisão |
| :----: | :------------------------------------: | :--------: | :--------: | :------------: | :-------------: |
|  1.0   | Criação do planejamento da avaliação | [João Vitor](https://github.com/Jauzimm), [Felipe Rodrigues](https://github.com/felipeJRdev) | 04/01/2025 |  |  |