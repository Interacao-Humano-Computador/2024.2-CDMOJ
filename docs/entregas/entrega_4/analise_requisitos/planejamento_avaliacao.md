# Planejamento da Avaliação da Análise de Tarefas

## Introdução

A avaliação de sistemas interativos é crucial para garantir que atendam aos critérios de qualidade e ofereçam uma boa experiência ao usuário. O framework DECIDE é uma metodologia eficiente para planejar e executar avaliações em IHC, permitindo identificar problemas e melhorar a usabilidade e a interface do sistema. 

Ao utilizar o DECIDE, é possível obter uma visão clara das necessidades dos usuários e alinhar o design do sistema com seus objetivos. Esse processo não só ajuda a detectar falhas, mas também assegura que o produto seja funcional e acessível, minimizando custos com correções futuras. Este documento tem como objetivo planejar a avaliação do CD-MOJ, garantindo que ele atenda às expectativas dos usuários.

## Objetivo

O principal objetivo desta avaliação é validar os fluxos descritos na HTA para o CD-MOJ, identificando possíveis inconsistências e coletando feedback dos usuários sobre os processos. Essa avaliação busca verificar se o sistema promove a **apropriação da tecnologia pelos usuários**, se apresenta **conformidade com padrões de usabilidade** e se oferece **alternativas de design** adequadas para minimizar problemas de interação e interface.

Os objetivos específicos incluem:

- Avaliar a correspondência entre as tarefas descritas na HTA e as ações dos usuários.
- Identificar possíveis dificuldades enfrentadas pelos usuários durante as interações com o CD-MOJ.
- Obter sugestões de melhorias com base na experiência prática dos usuários.

## Metodologia

Será utilizado o framework DECIDE para o planejamento dessa avaliação, estruturando o processo em seis etapas a serem seguidas.

![Figura do framework DECIDE](../../assets/Framework_DECIDE.jpeg)

# FRAMEWORK DECIDE

## D - Determinar os objetivos

A meta principal desta avaliação é detectar falhas de usabilidade no CD-MOJ e compreender como os usuários interagem com os elementos do sistema descritos na análise de tarefas. Assim, verificaremos se o sistema atende às necessidades, é funcional e proporciona aos usuários a realização eficaz de seus objetivos.

## E - Explorar as perguntas 

Com o objetivo definido, é necessário elaborar algumas perguntas específicas a serem respondidas durante a avaliação. Elas devem considerar o perfil dos usuarios-alvo e suas atividades. As perguntas são:

<font size="3"><p style="text-align: left">**Tabela 1**: Tabela de perguntas especificas a serem respondidas durante a avaliação.</p></font>

| Número | Pergunta | Resposta |
|:------:|:--------:|:--------:|
| 1 | As etapas descritas na tarefa refletem sua experiência real com o CD-MOJ? | [ ] Sim, [ ] Não |
| 2 | Alguma etapa lhe pareceu confusa ou desnecessária? Qual? | Pergunta discursiva |
| 3 | Quais dificuldades você enfrentou ao realizar a tarefa descrita? | Resposta discursiva |
| 4 | Há algo que você sugere incluir ou modificar nas etapas apresentadas? | Pergunta discursiva |
| 5 | A interface do sistema contribuiu para a realização eficiente da tarefa? Por quê? | Pergunta discursiva |

Autor(es): [João Vitor](https://github.com/Jauzimm), 2024.

## C - Escolher (Choose)

Para a realização da avaliação do CD-MOJ, será aplicado o método de investigação, combinando entrevistas estruturadas e observação de usuários, guiadas por um conjunto de perguntas previamente elaborado.

Essa abordagem possui a capacidade de coletar informações detalhadas e permite explorar questões mais aprofundadas relacionadas aos objetivos e desafios enfrentados pelos usuários. As entrevistas serão registradas por meio de gravações em áudio/vídeo e documentos escritos.

## I - Identificar

### Recrutamento

Para o recrutamento, serão selecionadas cinco pessoas, uma para cada análise de tarefa realizada pelos integrantes do grupo. O público-alvo será definido com base no perfil do usuário. As entrevistas serão conduzidas de forma online para a realização dessa atividade.

### Preparação

Após o teste piloto, os entrevistadores deverão se preparar para conduzir as entrevistas de forma estruturada, com base em um roteiro de perguntas. Eles serão responsáveis por realizar as perguntas e registrar as respostas dos usuários. A entrevista envolverá atividades do artefato de análise de tarefas.
Os papéis podem ser divididos entre uma ou duas pessoas, sendo uma responsável pelas perguntas e a outra pela coleta das respostas.

### Custos

Para a realização da avaliação, serão necessários dispositivos com acesso à internet, como notebooks ou computadores, para realizar e gravar as entrevistas, tanto dos entrevistadores quanto dos entrevistados. Além disso, será necessário garantir que os participantes tenham acesso a ferramentas de videoconferência, para facilitar a interação online. Por se tratar de uma avaliação online, os custos operacionais são consideravelmente reduzidos, uma vez que não há necessidade de infraestrutura física, deslocamentos ou materiais impressos.

### Prazos

Cada entrevistador conduzirá uma sessão com duração aproximada de 20 minutos. O cronograma será preenchido conforme a disponibilidade dos participantes.

<font size="3"><p style="text-align: left">**Tabela 2**: Tabela de prazos para cada integrante.</p></font>

| Entrevistador(es)                       | Entrevistado(s)           | Horário de Início | Horário de Fim | Data       | Local              |
|:--------------------------------------:|:-------------------------:|:----------------:|:--------------:|:----------:|:------------------:|
| [Felipe Rodrigues](https://github.com/felipeJRdev)  |  | A definir | A definir | 18/12/2024 | Plataforma Google Meet |
| [Jéssica Eveline](https://github.com/xzxjesse)      |  | A definir | A definir | 18/12/2024 | Plataforma Google Meet |
| [João Vitor](https://github.com/Jauzimm)            |  | A definir | A definir | 18/12/2024 | Plataforma Google Meet  |
| [Ruan Carvalho](https://github.com/Ruan-Carvalho)   |  | A definir | A definir | 18/12/2024 | Plataforma Google Meet  |
| [Marcelo Adrian](https://github.com/Marcelo-Adrian) |  | A definir | A definir | 18/12/2024 | Plataforma Google Meet |

Autor(es): [João Vitor](https://github.com/Jauzimm), 2024.

## D - Decidir como lidar com as questões éticas

Os participantes serão informados sobre os objetivos da avaliação e o uso de suas respostas. Um termo de consentimento será apresentado, garantindo o sigilo e a utilização ética das informações coletadas.

## E - Avaliar (Evaluate)

Após a coleta de dados, as respostas serão analisadas para identificar padrões e discrepâncias. O avaliador considerará a confiabilidade dos dados, a validade interna, externa e ecológica do estudo, garantindo que os resultados sejam consistentes, precisos e aplicáveis a contextos semelhantes. Os problemas identificados serão classificados por gravidade, e as sugestões dos participantes serão priorizadas para a implementação de melhorias no CD-MOJ.
## Planejamento do Teste Piloto

Antes de realizar a avaliação completa, é fundamental conduzir um teste piloto. Esse teste tem como objetivo validar o planejamento da avaliação, garantir que todos os procedimentos estão claros e funcionais, e permitir ajustes necessários. Além disso, o teste piloto ajuda a identificar possíveis falhas nos métodos, questões de usabilidade e a eficácia do roteiro de entrevista. Segue a tabela abaixo com a marcação do teste piloto.

<font size="3"><p style="text-align: left">**Tabela 3**: Tabela do planejamento do teste piloto.</p></font>

| Ordem | Data       | Horário de Início e Fim | Local                              | Entrevistadores | Entrevistado |
|:-----:|:----------:|:-----------------------:|:----------------------------------:|:---------------:|:------------:|
|   1   | 14/12/2024 | 21:00 - 21:15          | Google meet | [João Vitor](https://github.com/Jauzimm) | [Felipe Rodrigues](https://github.com/felipeJRdev) |

Autor(es): [João Vitor](https://github.com/Jauzimm), 2024.

## Bibliografia

BARBOSA, Simone Diniz Junqueira; DA SILVA, Bruno Santana. Planejamento da avaliação de IHC. In: INTERAÇÃO Humano-Computador. Rio de Janeiro: Elsevier Editora, 2010.

## Histórico de Versão

| Versão |               Descrição                |   Autor    |    Data    |    Revisor     | Data de revisão |
| :----: | :------------------------------------: | :--------: | :--------: | :------------: | :-------------: |
|  1.0   | Criação do planejamento da avaliação | [João Vitor](https://github.com/Jauzimm) | 10/12/2024 | [Marcelo Adrian](https://github.com/Marcelo-Adrian) | 10/12/2024 |
